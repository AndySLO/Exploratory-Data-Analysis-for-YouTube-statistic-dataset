{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import six\n",
    "sns.set()\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/andyslo/Documents/DATA\")\n",
    "AllCSV  = [i for i in glob.glob('*.{}'.format('csv'))]\n",
    "AllCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataframes = []                               # list to store each data frame separately\n",
    "for csv in AllCSV:\n",
    "    df = pd.read_csv(csv, encoding='latin-1')\n",
    "    df['country'] = csv[0:2]                      # adding column 'country', each dataset could be identified uniquely\n",
    "    all_dataframes.append(df)\n",
    "all_dataframes[0].head()                          # index 0 to 9 for [CA, DE, FR, GB, IN, JP, KR, MX, RU, US] datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in all_dataframes:\n",
    "    # video_id \n",
    "    df['video_id'] = df['video_id'].astype('str') \n",
    "    \n",
    "    # trending date\n",
    "    df['trending_date'] = df['trending_date'].astype('str') \n",
    "    date_pieces = (df['trending_date']\n",
    "                   .str.split('.')\n",
    "                  )\n",
    "    df['Year'] = date_pieces.str[0].astype(int)\n",
    "    df['Day'] = date_pieces.str[1].astype(int)\n",
    "    df['Month'] = date_pieces.str[2].astype(int)\n",
    "    updatedyear = []\n",
    "    for i in range(len(df)) : \n",
    "        y = df.loc[i, \"Year\"]\n",
    "        newy = y+2000\n",
    "        updatedyear.append(newy)\n",
    "    for i in range(len(df)):\n",
    "        newy = updatedyear[i]\n",
    "        tr = df.loc[i, \"Year\"]\n",
    "        df['Year'].replace(to_replace = tr, value = newy, inplace=True)\n",
    "    del df['trending_date']\n",
    "    df['trending_date'] = pd.to_datetime(df[['Year', 'Month', 'Day']], format = \"%Y-%m-%d\")\n",
    "    del df['Year']\n",
    "    del df['Day']\n",
    "    del df['Month']\n",
    "    \n",
    "    #title\n",
    "    df['title'] = df['title'].astype('str')\n",
    "    #channel_title\n",
    "    df['channel_title'] = df['channel_title'].astype('str')\n",
    "    #category_id\n",
    "    df['category_id'] = df['category_id'].astype(str) \n",
    "    \n",
    "    #tags\n",
    "    df['tags'] = df['tags'].astype('str')\n",
    "    \n",
    "    # views, likes, dislikes, comment_count are already in correct data types i.e int64\n",
    "    \n",
    "    #thumbnail_link\n",
    "    df['thumbnail_link'] = df['thumbnail_link'].astype('str') \n",
    "    \n",
    "    #description\n",
    "    df['description'] = df['description'].astype('str')\n",
    "    \n",
    "    # Changing comments_disabled, ratings_disabled, video_error_or_removed from bool to categorical\n",
    "    df['comments_disabled'] = df['comments_disabled'].astype('category') \n",
    "    df['ratings_disabled'] = df['ratings_disabled'].astype('category') \n",
    "    df['video_error_or_removed'] = df['video_error_or_removed'].astype('category') \n",
    "    \n",
    "    # publish_time \n",
    "    df['publish_time'] = pd.to_datetime(df['publish_time'], errors='coerce', format='%Y-%m-%dT%H:%M:%S.%fZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in all_dataframes:\n",
    "    df.insert(4, 'publish_date', df['publish_time'].dt.date) # loc, column name, values for column to be inserted\n",
    "    df['publish_time'] = df['publish_time'].dt.time\n",
    "# Changing data type for 'publish_date' from object to 'datetime64[ns]'\n",
    "for df in all_dataframes:\n",
    "     df['publish_date'] = pd.to_datetime(df['publish_date'], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use any index from 0 to 9 inclusive (for each of the 10 dataframes\n",
    "all_dataframes[1].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in all_dataframes:\n",
    "    df.set_index('video_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in all_dataframes:\n",
    "    sns.heatmap(df.isnull(), cbar=False)\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(all_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making copy of original dataframe\n",
    "backup_df = combined_df.reset_index().sort_values('trending_date', ascending=False).set_index('video_id')\n",
    "# Sorting according to latest trending date while removing duplicates\n",
    "combined_df = combined_df.reset_index().sort_values('trending_date', ascending=False).drop_duplicates('video_id',keep='first').set_index('video_id')\n",
    "# Doing the same above operation for each of the individual dataframes in the list we created earlier\n",
    "for df in all_dataframes:\n",
    "    df = df.reset_index().sort_values('trending_date', ascending=False).set_index('video_id')\n",
    "# Printing results\n",
    "combined_df[['publish_date','publish_time','trending_date', 'country']].head()\n",
    "# It can be seen that latest publications and trending information is at the top now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "with open('US_category_id.json', 'r') as f:  # reading one randomly selected json files to make sense of its contents\n",
    "    data = f.read()\n",
    "# parse file\n",
    "obj = json.loads(data)\n",
    "# printing\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id = {}\n",
    "with open('DE_category_id.json', 'r') as f:\n",
    "    d = json.load(f)\n",
    "    for category in d['items']:\n",
    "        category_id[category['id']] = category['snippet']['title']\n",
    "combined_df.insert(2, 'category', combined_df['category_id'].map(category_id))\n",
    "backup_df.insert(2, 'category', backup_df['category_id'].map(category_id))\n",
    "for df in all_dataframes:\n",
    "    df.insert(2, 'category', df['category_id'].map(category_id))\n",
    "# Printing cleaned combined dataframe\n",
    "combined_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating total likes for each category\n",
    "likesdf = combined_df.groupby('category')['likes'].agg('sum')\n",
    "# calculating total dislikes for each category\n",
    "dislikesdf = combined_df.groupby('category')['dislikes'].agg('sum')\n",
    "# calculating ratios of likes to dislikes\n",
    "ratiodf = likesdf/dislikesdf \n",
    "# most liked category to appear on top\n",
    "ratiodf = ratiodf.sort_values(ascending=False).reset_index()\n",
    "# plotting bar chart\n",
    "ratiodf.columns = ['category','ratio']\n",
    "plt.subplots(figsize=(10, 15))\n",
    "sns.barplot(x=\"ratio\", y=\"category\", data=ratiodf,\n",
    "            label=\"Likes-Dislikes Ratio\", color=\"r\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting names of all countries\n",
    "countries = []\n",
    "allcsv = [i for i in glob.glob('*.{}'.format('csv'))]\n",
    "for csv in allcsv:\n",
    "    c = csv[0:2]\n",
    "    countries.append(c)\n",
    "    \n",
    "for country in countries:\n",
    "        tempdf = combined_df[combined_df['country']==country]['category'].value_counts().reset_index()\n",
    "        ax = sns.barplot(y=tempdf['index'], x=tempdf['category'], data=tempdf, orient='h')\n",
    "        plt.xlabel(\"Number of Videos\")\n",
    "        plt.ylabel(\"Categories\")\n",
    "        plt.title(\"Catogories of trend videos in \" + country)\n",
    "        plt.figure()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating days between publish and trending date\n",
    "temporary = []\n",
    "for data in all_dataframes:\n",
    "    temp = data\n",
    "    temp['timespan'] = (temp['trending_date'] - temp['publish_date']).dt.days\n",
    "    temporary.append(temp)\n",
    "# Plotting\n",
    "to_trending = temporary[0].sample(1000).groupby('video_id').timespan.max() # CA\n",
    "sns_ax = sns.boxplot(y = to_trending)\n",
    "_ = sns_ax.set(yscale = \"log\")\n",
    "plt.show()\n",
    "_ = sns.distplot(to_trending.value_counts(),bins='rice',kde=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = combined_df\n",
    "temp = temp.groupby('country')['views','likes','dislikes', 'comment_count'].apply(lambda x: x.astype(int).sum())\n",
    "temp = temp.sort_values(by='comment_count', ascending=False).head()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = combined_df\n",
    "temp = temp.groupby('category')['views','likes','dislikes', 'comment_count'].apply(lambda x: x.astype(int).sum())\n",
    "temp = temp.sort_values(by='comment_count', ascending=False).head()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tags\n",
    "col = ['views', 'likes', 'dislikes', 'comment_count']\n",
    "corr = combined_df[col].corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_bar(x,y,title):\n",
    "    plt.figure(figsize = (13,11))\n",
    "    sns.barplot(x = x, y = y)\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.category.value_counts().index\n",
    "y = df.category.value_counts().values\n",
    "title = \"Categories\"\n",
    "view_bar(x,y,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"category\"] == 'Music'][['trending_date', 'video_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"channel_title\"] == 'TheEllenShow'][['channel_title', 'trending_date', 'video_id', 'country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset =\"video_id\", keep = 'first', inplace = True)\n",
    "df[df[\"channel_title\"] == 'TheEllenShow'][['channel_title', 'trending_date', 'video_id', 'country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset =\"video_id\", keep = 'first', inplace = True)\n",
    "df[df[\"channel_title\"] == 'TheEllenShow'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CA_tempdf=[CA_tempdf[\"category\"] == 'Music'][['channel_title', 'trending_date']] ---- cutout\n",
    "CA_tempdf = combined_df[combined_df['country']== 'CA']\n",
    "\n",
    "CA_tempdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop_duplicates(subset =\"video_id\", keep = 'first', inplace = True)\n",
    "combined_df[combined_df[\"channel_title\"] == 'TheEllenShow'][['channel_title', 'trending_date', 'video_id', 'country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.channel_title.value_counts().head(10).index\n",
    "y = df.channel_title.value_counts().head(10).values\n",
    "title = \"Top 10 Channels\"\n",
    "view_bar(x,y,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_df = pd.read_csv('/Users/andyslo/Documents/DATA/CAvideos.csv')\n",
    "\n",
    "sort_by_likes = CA_df.sort_values(by =\"likes\" , ascending = False).drop_duplicates('title', keep = 'first')\n",
    "x = sort_by_likes['title'].head(10)\n",
    "y = sort_by_likes['likes'].head(10)\n",
    "title = \"Most liked videos\"\n",
    "view_bar(x,y,title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = CA_df.channel_title.value_counts().head(10).index\n",
    "y = CA_df.channel_title.value_counts().head(10).values\n",
    "title = \"Top 10 Channels in Canada\"\n",
    "view_bar(x,y,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_df = pd.read_csv('/Users/andyslo/Documents/DATA/DEvideos.csv')\n",
    "\n",
    "sort_by_likes = DE_df.sort_values(by =\"likes\" , ascending = False).drop_duplicates('title', keep = 'first')\n",
    "x = sort_by_likes['title'].head(10)\n",
    "y = sort_by_likes['likes'].head(10)\n",
    "title = \"Most liked videos\"\n",
    "view_bar(x,y,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = DE_df.channel_title.value_counts().head(10).index\n",
    "y = DE_df.channel_title.value_counts().head(10).values\n",
    "title = \"Top 10 Channels in Germany\"\n",
    "view_bar(x,y,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_df = pd.read_csv('/Users/andyslo/Documents/DATA/CAvideos.csv')\n",
    "video_stat = CA_df.sort_values('likes', ascending=False)\n",
    "# removing dublicates\n",
    "video_stat.drop_duplicates(subset =\"video_id\", keep = 'first', inplace = True)\n",
    "#printing TOP 50\n",
    "video_stat.head(50)[['video_id', 'trending_date', 'likes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_df = pd.read_csv('/Users/andyslo/Documents/DATA/CAvideos.csv')\n",
    "video_stat = CA_df.sort_values('dislikes', ascending=False)\n",
    "# removing dublicates\n",
    "video_stat.drop_duplicates(subset =\"video_id\", keep = 'first', inplace = True)\n",
    "#printing TOP 50\n",
    "video_stat.head(50)[['video_id', 'trending_date', 'dislikes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_df = pd.read_csv('/Users/andyslo/Documents/DATA/GBvideos.csv')\n",
    "video_stat = GB_df.sort_values('likes', ascending=False)\n",
    "# removing dublicates\n",
    "video_stat.drop_duplicates(subset =\"video_id\", keep = 'first', inplace = True)\n",
    "#printing TOP 50\n",
    "video_stat.head(50)[['video_id', 'trending_date', 'likes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_df = pd.read_csv('/Users/andyslo/Documents/DATA/GBvideos.csv')\n",
    "video_stat = GB_df.sort_values('dislikes', ascending=False)\n",
    "# removing dublicates\n",
    "video_stat.drop_duplicates(subset =\"video_id\", keep = 'first', inplace = True)\n",
    "#printing TOP 50\n",
    "video_stat.head(50)[['video_id', 'trending_date', 'dislikes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_df = pd.read_csv('/Users/andyslo/Documents/DATA/USvideos.csv')\n",
    "video_stat = US_df.sort_values('likes', ascending=False)\n",
    "# removing dublicates\n",
    "video_stat.drop_duplicates(subset =\"video_id\", keep = 'first', inplace = True)\n",
    "#printing TOP 50\n",
    "video_stat.head(50)[['video_id', 'trending_date', 'likes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_df = pd.read_csv('/Users/andyslo/Documents/DATA/USvideos.csv')\n",
    "video_stat = US_df.sort_values('dislikes', ascending=False)\n",
    "# removing dublicates\n",
    "video_stat.drop_duplicates(subset =\"video_id\", keep = 'first', inplace = True)\n",
    "#printing TOP 50\n",
    "video_stat.head(50)[['video_id', 'trending_date', 'dislikes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.category.value_counts().index\n",
    "y = df.category.value_counts().valuesdf.drop_duplicates(subset =\"video_id\", keep = 'first', inplace = True)\n",
    "title = \"Categories\"\n",
    "view_bar(x,y,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset =\"video_id\", keep = 'first', inplace = True)\n",
    "df[df['category'] == 'Music'][['channel_title', 'trending_date', 'video_id', 'country']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df.groupby('category')\n",
    "print(category_id)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "037156c89671e15fee14a445e9d30ee73db7fb574492cc1717f32e36ea63ac81"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
